{
	"jobConfig": {
		"name": "ai4i_job",
		"description": "",
		"role": "arn:aws:iam::940482431470:role/service-role/AWSGlueServiceRole-S3-Glue",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "ai4i_job.py",
		"scriptLocation": "s3://aws-glue-assets-940482431470-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-11-18T18:45:40.047Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-940482431470-us-east-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-940482431470-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"sourceControlDetails": {
			"Provider": "GITHUB",
			"Repository": "",
			"Branch": "",
			"Folder": "ai4i_job",
			"LastCommitId": "c34c175f1e2a63b3c076bd8e413c32142721398e"
		},
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql.functions import col, when\n\n# @params: [JOB_NAME]\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\n# Parameters for Input and Output\ninput_database = \"ai4i_database\"\ninput_table_name = \"machine_failure_source_bucket\"\noutput_s3_path = \"s3://machine-failure-transformed-bucket/TransformedData/\"\n\ndatasource = glueContext.create_dynamic_frame.from_catalog(\n    database=input_database,\n    table_name=input_table_name\n)\n\ndf = datasource.toDF()\n\n# Debugging\nprint(\"Columns in DataFrame:\", df.columns)\n\ndf = df.withColumnRenamed(\"process temperature [k]\", \"process_temperature\") \\\n       .withColumnRenamed(\"air temperature [k]\", \"air_temperature\") \\\n       .withColumnRenamed(\"rotational speed [rpm]\", \"rotational_speed\") \\\n       .withColumnRenamed(\"torque [nm]\", \"torque\")\n\ndf = df.withColumn(\n    'Temp_Diff',\n    col('process_temperature') - col('air_temperature')\n).withColumn(\n    'Power',\n    col('torque') * (col('rotational_speed') * 2 * 3.14159 / 60)\n).withColumn(\n    'Failure',\n    when(\n        (col('twf') == 1) | (col('hdf') == 1) | (col('pwf') == 1) |\n        (col('osf') == 1) | (col('rnf') == 1), 1\n    ).otherwise(0)\n)\n\ncols_to_drop = ['UDI', 'Product ID', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\ndf = df.drop(*cols_to_drop)\n\n# Debugging: Show transformed data\nprint(\"Sample data after dropping columns:\")\ndf.show(5)\n\ndf.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_s3_path)\n\n# Commit the job\njob.commit()\n"
}